############################################
# LIEBERMAN LAB SNAKEFILE FOR MAPPING STEP #
############################################
''' PRE-SNAKEMAKE '''

import sys
import os
SCRIPTS_DIRECTORY = "./scripts"
sys.path.insert(0, SCRIPTS_DIRECTORY)

# from import read_samplesCSV # not needed since this function is in the next file
from mapping_modules import *

## Define couple of lists from samples.csv
## Format: Path,Sample,ReferenceGenome,ProviderName,Subject

## modified format to Path,Sample,ReferenceGenome,OutGroup 
## NOTE: samples should be deduplicated bam files
spls = "samples.csv"
[PATH_ls,SAMPLE_ls,REF_Genome_ls,PROVIDER_ls,CLADEID_ls,OUTGROUP_ls] = read_samplesCSV(spls)
ref_genome_to_non_outgroup_bams_dict = get_non_outgroup_bams_for_freebayes(SAMPLE_ls, REF_Genome_ls, OUTGROUP_ls)
[REF_Genome_ext_ls, SAMPLE_ext_ls] = parse_multi_genome_smpls(SAMPLE_ls, REF_Genome_ls)
# Write sample_info.csv for each sample
split_samplesCSV(PATH_ls,SAMPLE_ls,REF_Genome_ls,PROVIDER_ls,CLADEID_ls)
CLADES_ls = set(CLADEID_ls)

# grab current working directory for qc rules to use
current_directory = os.getcwd()


''' SNAKEMAKE '''

rule all:
  input:
    expand("data/{sampleID}/{sampleID}.bam",sampleID=SAMPLE_ls),
    expand("data/{sampleID}/{sampleID}.bam.bai",sampleID=SAMPLE_ls),
    expand("5-quals/{sampleID}_ref_{reference}_aligned.sorted.strain.variant.quals.npz", zip, sampleID=SAMPLE_ls, reference=REF_Genome_ls),
    expand("6-diversity/{sampleID}_ref_{reference}_aligned.sorted.strain.variant.diversity.npz", zip, sampleID=SAMPLE_ls, reference=REF_Genome_ls),
    expand("4-vcf/ref_{reference}_freebayes_raw_joint_calls.vcf",reference=set(REF_Genome_ext_ls)),
    "../case/samples_case.csv",
    "cleanUp_done.txt",


rule make_data_links_ancient:
  input:
    sample_info_csv="data/{sampleID}/sample_info.csv",
  output:
    bams="data/{sampleID}/{sampleID}.bam",
    bais="data/{sampleID}/{sampleID}.bam.bai",
  group:
    'make_link_group',
  run:
    ## create symbolic links
    with open(input.sample_info_csv,'r') as f:
      this_sample_info = f.readline() # only one line to read
    this_sample_info = this_sample_info.strip('\n').split(',')
    path = this_sample_info[0] # remember python indexing starts at 0
    sample = this_sample_info[1]
    providername = this_sample_info[3]
    print(path + '\n' + sample)
    # make links
    makelink_ancient(path, sample, providername)

rule create_freebayes_input:
  input:
    non_outgroup_bam_ls=lambda wildcards: expand("data/{sampleID}/{sampleID}.bam",reference=wildcards.reference, sampleID=ref_genome_to_non_outgroup_bams_dict[wildcards.reference]),
  output:
    non_outgroup_bam_file="3-freebayes_input/ref_{reference}_non_outgroup_bams.txt",
  group:
    'pileup_and_filter',
  shell:
    "for BAM in {input.non_outgroup_bam_ls}; do echo ${{BAM}} >> {output.non_outgroup_bam_file} ; done ;"

rule freebayes_indels:
  input:
    non_outgroup_bam_list=rules.create_freebayes_input.output.non_outgroup_bam_file, 
    fai="/nexus/posix0/MPIIB-keylab/reference_genomes/{reference}/genome.fasta.fai",
    ref="/nexus/posix0/MPIIB-keylab/reference_genomes/{reference}/genome.fasta",
  output:
    vcf_indels="4-vcf/ref_{reference}_non_outgroup_indels_complex.vcf.gz",
    vcf_raw="4-vcf/ref_{reference}_freebayes_raw_joint_calls.vcf",
  conda:
    "envs/freebayes.yaml", 
  shell:
    " freebayes-parallel <(fasta_generate_regions.py {input.fai} 100000) 36 -f {input.ref} -p 1 -L {input.non_outgroup_bam_list} > {output.vcf_raw} ;"
    " egrep '#|ins|del|complex' {output.vcf_raw} | gzip -c > {output.vcf_indels} ;"

rule mpileup2vcf_ancient:
  input:
    bam=rules.make_data_links_ancient.output.bams,
    ref="/nexus/posix0/MPIIB-keylab/reference_genomes/{reference}/genome.fasta",
  output:
    pileup="4-vcf/{sampleID}_ref_{reference}_aligned.sorted.pileup",
    variants="4-vcf/{sampleID}_ref_{reference}_aligned.sorted.strain.variant.vcf.gz",
    vcf_strain="4-vcf/{sampleID}_ref_{reference}_aligned.sorted.strain.vcf.gz",
  group:
    'pileup_and_filter', 
  params:
    vcf_raw="4-vcf/{sampleID}_ref_{reference}_aligned.sorted.strain.gz",
  conda:
    "envs/samtools15_bcftools12.yaml"
  shell:
    " samtools mpileup -q30 -x -s -O -d3000 -f {input.ref} {input.bam} > {output.pileup} ;"
    " samtools mpileup -q30 -t SP -d3000 -vf {input.ref} {input.bam} > {params.vcf_raw} ;"
    " bcftools call -c -Oz -o {output.vcf_strain} {params.vcf_raw} ;"
    " bcftools view -Oz -v snps -q .1 {output.vcf_strain} > {output.variants} ;"
    " tabix -p vcf {output.variants} ;"
    " rm {params.vcf_raw}"

# strain.vcf ==> vcf_to_quals.m ==>.quals.npz
rule vcf2quals_ancient:
  input:
    vcf_strain = rules.mpileup2vcf_ancient.output.vcf_strain,
  params:
    refGenomeDir="/nexus/posix0/MPIIB-keylab/reference_genomes/{reference}/"
  output:
    file_quals = "5-quals/{sampleID}_ref_{reference}_aligned.sorted.strain.variant.quals.npz",
  group:
    'pileup_and_filter',
  run:
    from vcf_to_quals_snakemake import vcf_to_quals_snakemake
    vcf_to_quals_snakemake(sample_path_to_vcf = input.vcf_strain, sample_path_to_quals = output.file_quals, REF_GENOME_DIRECTORY = params.refGenomeDir)

# strain.pileup ==> pileup_to_diversity.m ==> diversity.mat
rule pileup2diversity_matrix_ancient:
  input:
    pileup = rules.mpileup2vcf_ancient.output.pileup,
  params:
    refGenomeDir="/nexus/posix0/MPIIB-keylab/reference_genomes/{reference}/",
  output:
    file_diversity = "6-diversity/{sampleID}_ref_{reference}_aligned.sorted.strain.variant.diversity.npz",
    file_coverage = "6-diversity/{sampleID}_ref_{reference}_aligned.sorted.strain.variant.coverage.npz",
  group:
    'pileup_and_filter',
  run:
    from pileup_to_diversity_matrix_snakemake import pileup_to_div_matrix_snakemake
    pileup_to_div_matrix_snakemake(sample_path_to_pileup = input.pileup, sample_path_to_diversity =  output.file_diversity, sample_path_to_coverage = output.file_coverage, ref_genome_directory = params.refGenomeDir)

rule remove_pileup_ancient:
  input:
    pileup = rules.mpileup2vcf_ancient.output.pileup,
  params:
    file_diversity = "6-diversity/{sampleID}_ref_{reference}_aligned.sorted.strain.variant.diversity.npz",
    file_coverage = "6-diversity/{sampleID}_ref_{reference}_aligned.sorted.strain.variant.coverage.npz",
  group:
    'pileup_and_filter',
  shell:
    "rm {input.pileup};"

rule cleanUp_ancient:
  input:
    part1 = expand("5-quals/{sampleID}_ref_{reference}_aligned.sorted.strain.variant.quals.npz", zip, sampleID=SAMPLE_ls, reference=REF_Genome_ls),  # input not used, only required so snakemake waits with clean up until the end
    part2 = expand("6-diversity/{sampleID}_ref_{reference}_aligned.sorted.strain.variant.diversity.npz", zip, sampleID=SAMPLE_ls, reference=REF_Genome_ls),  # input not used, only required so snakemake waits with clean up until the end
  output:
    "cleanUp_done.txt",
  shell:
    " touch {output} ;"

rule generate_next_samplescsv:
  input: 
    csv = "samples.csv",
  output:
    case_csv = "../case/samples_case.csv",
  shell: 
    """ mkdir -p ../case ;"""
    """ echo 'Path,Sample,ReferenceGenome,Outgroup' > {output.case_csv} ;"""
    " dir=$(pwd) ;"
    """ awk -v dir="$dir" 'BEGIN{{FS=OFS=","}} NR>1 {{print dir,$2,$3,$6}}' {input.csv} >> {output.case_csv} ;"""
